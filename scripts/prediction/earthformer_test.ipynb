{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ede748",
   "metadata": {},
   "source": [
    "# Predicting Archetypes with Earthformer\n",
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b4b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import xarray as xr\n",
    "\n",
    "# import both nc's\n",
    "stream_path = \"../../data/lentis_stream250_JJA_2deg_101_deseason_smsubd_sqrtcosw.nc\"\n",
    "dataset_stream = xr.open_dataset(stream_path)\n",
    "\n",
    "tas_path = \"../../data/lentis_tas_JJA_2deg_101_deseason.nc\"\n",
    "dataset_tas = xr.open_dataset(tas_path)\n",
    "\n",
    "# get S_PCHA from archetypes file\n",
    "with h5py.File('../../data/pcha_results_8a.hdf5', 'r') as f: # run from mmi393 directory or gives error\n",
    "        S_PCHA = f['/S_PCHA'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76dc13",
   "metadata": {},
   "source": [
    "Join TAS and stream function data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2991d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3480835\n",
      "0.13922119\n",
      "-0.3480835\n",
      "0.13922119\n"
     ]
    }
   ],
   "source": [
    "# group indices based on whichever archetype is maximum there\n",
    "arch_indices = np.argmax(S_PCHA, axis=0)\n",
    "\n",
    "# sanity check part 1: these results should be the same in part 2\n",
    "print(dataset_tas.isel(time=123)['tas'].isel(lon=0, lat=0).values)\n",
    "print(dataset_tas.isel(time=74)['tas'].isel(lon=4, lat=8).values)\n",
    "\n",
    "# join the nc's together\n",
    "dataset_comb = dataset_stream.assign(tas=dataset_tas['tas'])\n",
    "\n",
    "# sanity check part 2\n",
    "print(dataset_comb.isel(time=123)['tas'].isel(lon=0, lat=0).values)\n",
    "print(dataset_comb.isel(time=74)['tas'].isel(lon=4, lat=8).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45647cd",
   "metadata": {},
   "source": [
    "Add labels from AA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addde090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 5 0\n",
      "0 5 5 0\n",
      "0 5 5 0\n"
     ]
    }
   ],
   "source": [
    "# sanity check 1\n",
    "print(arch_indices[0], arch_indices[5], arch_indices[6], arch_indices[9119])\n",
    "\n",
    "arch_da = xr.DataArray(arch_indices, dims=\"time\", coords={\"time\": dataset_comb.time})\n",
    "# sanity check 2 \n",
    "print(arch_da.isel(time=0).values, arch_da.isel(time=5).values, arch_da.isel(time=6).values, arch_da.isel(time=9119).values)\n",
    "\n",
    "# calculate the mean for each archetype's group\n",
    "dataset_comb_labeled = dataset_comb.assign(archetype=arch_da)\n",
    "\n",
    "# sanity check 3\n",
    "print(dataset_comb_labeled.isel(time=0)['archetype'].values,\n",
    "      dataset_comb_labeled.isel(time=5)['archetype'].values,\n",
    "      dataset_comb_labeled.isel(time=6)['archetype'].values,\n",
    "      dataset_comb_labeled.isel(time=9119)['archetype'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593acae1",
   "metadata": {},
   "source": [
    "## Dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bd6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scistor/ivm/mmi393/.conda/envs/netcdf_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae04c65e",
   "metadata": {},
   "source": [
    "From xarray dataset to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6866d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9200, 29, 170, 2])\n"
     ]
    }
   ],
   "source": [
    "stream = dataset_comb['stream'].squeeze('plev').values  # (T, lat, lon)\n",
    "tas = dataset_comb['tas'].values                        # (T, lat, lon)\n",
    "\n",
    "# Extract and squeeze stream function\n",
    "stream = dataset_comb['stream'].squeeze('plev').values  # (T, H, W)\n",
    "tas = dataset_comb['tas'].values                        # (T, H, W)\n",
    "\n",
    "# Stack the variables along the channel axis\n",
    "x_np = np.stack([stream, tas], axis=-1)  # shape: (T, H, W, C) where C = 2\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "x_tensor = torch.from_numpy(x_np).float()\n",
    "\n",
    "print(x_tensor.shape)  # (T=9200, H=29, W=170, C=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d8b77",
   "metadata": {},
   "source": [
    "Target construction\n",
    "\n",
    "If t+7 is belongs to another year, exclude example from labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58ececb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_final shape: torch.Size([8500, 29, 170, 2])\n",
      "y_final shape: torch.Size([8500])\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106]\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "l = 7  # lead time\n",
    "time = dataset_comb['time'].values  # format: datetime64\n",
    "arch_labels = arch_da.values        # (9200,)\n",
    "\n",
    "x_all = x_tensor  # shape: (T, H, W, C)\n",
    "x_list = []\n",
    "y_list = []\n",
    "kept_time_indices = []\n",
    "\n",
    "# Makes it so that examples from different years do not get combined\n",
    "# TODO Add data from September to include last week of August?\n",
    "for t in range(len(time) - l):\n",
    "    target_time = time[t] + np.timedelta64(l, 'D')\n",
    "    if time[t + l] == target_time:\n",
    "        x_list.append(x_all[t])\n",
    "        y_list.append(arch_labels[t + l])\n",
    "        kept_time_indices.append(t)\n",
    "\n",
    "# Stack into tensors\n",
    "x_final = torch.stack(x_list)              # shape: (N, H, W, C)\n",
    "y_final = torch.tensor(y_list, dtype=torch.long)  # shape: (N,)\n",
    "\n",
    "print(f\"x_final shape: {x_final.shape}\") # approx. 8% of the dataset is cut\n",
    "print(f\"y_final shape: {y_final.shape}\")\n",
    "print(kept_time_indices[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedebd74",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb05717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split x&y into train/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17678ec",
   "metadata": {},
   "source": [
    "## Using Earthformer\n",
    "Import Earthformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d45dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl_module' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m download(url\u001b[38;5;241m=\u001b[39mpretrained_checkpoint_url, path\u001b[38;5;241m=\u001b[39mlocal_checkpoint_path)\n\u001b[1;32m     12\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(local_checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m \u001b[43mpl_module\u001b[49m\u001b[38;5;241m.\u001b[39mtorch_nn_module\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict\u001b[38;5;241m=\u001b[39mstate_dict)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl_module' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from earthformer.cuboid_transformer.cuboid_transformer import CuboidTransformerModel\n",
    "#from earthformer.train_cuboid_earthnet import CuboidEarthNet2021PLModule\n",
    "from earthformer.utils.utils import download\n",
    "\n",
    "save_dir = \"./experiments\"\n",
    "\n",
    "pretrained_checkpoint_url = \"https://earthformer.s3.amazonaws.com/pretrained_checkpoints/earthformer_earthnet2021.pt\"\n",
    "local_checkpoint_path = os.path.join(save_dir, \"earthformer_earthnet2021.pt\")\n",
    "download(url=pretrained_checkpoint_url, path=local_checkpoint_path)\n",
    "\n",
    "state_dict = torch.load(local_checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "#pl_module.torch_nn_module.load_state_dict(state_dict=state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1e064",
   "metadata": {},
   "source": [
    "Initialize Earthformer model with the correct shapes, load pretrained weights where applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9056a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO figure out the proper initialization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCuboidTransformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/netcdf_env/lib/python3.9/site-packages/earthformer/cuboid_transformer/cuboid_transformer.py:2894\u001b[0m, in \u001b[0;36mCuboidTransformerModel.__init__\u001b[0;34m(self, input_shape, target_shape, base_units, block_units, scale_alpha, num_heads, attn_drop, proj_drop, ffn_drop, downsample, downsample_type, upsample_type, upsample_kernel_size, enc_depth, enc_attn_patterns, enc_cuboid_size, enc_cuboid_strategy, enc_shift_size, enc_use_inter_ffn, dec_depth, dec_cross_start, dec_self_attn_patterns, dec_self_cuboid_size, dec_self_cuboid_strategy, dec_self_shift_size, dec_cross_attn_patterns, dec_cross_cuboid_hw, dec_cross_cuboid_strategy, dec_cross_shift_hw, dec_cross_n_temporal, dec_cross_last_n_frames, dec_use_inter_ffn, dec_hierarchical_pos_embed, num_global_vectors, use_dec_self_global, dec_self_update_global, use_dec_cross_global, use_global_vector_ffn, use_global_self_attn, separate_global_qkv, global_dim_ratio, z_init_method, initial_downsample_type, initial_downsample_activation, initial_downsample_scale, initial_downsample_conv_layers, final_upsample_conv_layers, initial_downsample_stack_conv_num_layers, initial_downsample_stack_conv_dim_list, initial_downsample_stack_conv_downscale_list, initial_downsample_stack_conv_num_conv_list, ffn_activation, gated_ffn, norm_layer, padding_type, pos_embed_type, checkpoint_level, use_relative_pos, self_attn_use_final_proj, dec_use_first_self_attn, attn_linear_init_mode, ffn_linear_init_mode, conv_init_mode, down_up_linear_init_mode, norm_init_mode)\u001b[0m\n\u001b[1;32m   2891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_up_linear_init_mode \u001b[38;5;241m=\u001b[39m down_up_linear_init_mode\n\u001b[1;32m   2892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_init_mode \u001b[38;5;241m=\u001b[39m norm_init_mode\n\u001b[0;32m-> 2894\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(enc_depth) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dec_depth)\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_units \u001b[38;5;241m=\u001b[39m base_units\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_global_vectors \u001b[38;5;241m=\u001b[39m num_global_vectors\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO figure out the proper initialization\n",
    "model = CuboidTransformerModel(input_shape=(1, x_final.shape[1], x_final.shape[2], x_final.shape[3]),\n",
    "                               target_shape=(1, x_final.shape[1], x_final.shape[2], x_final.shape[3]),\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b6044",
   "metadata": {},
   "source": [
    "Adapt Earthformer to classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab29d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = S_PCHA.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthformerClassifier(nn.Module):\n",
    "    def __init__(self, earthformer_model, num_classes=n_classes):\n",
    "        super().__init__()\n",
    "        self.model = earthformer_model\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 1, 1))  # Pool over T, H, W\n",
    "        self.classifier = nn.Linear(self.model.target_shape[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)  # (B, T_out, H, W, C_out)\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # → [B, C_out, T_out, H, W]\n",
    "        x = self.pool(x).squeeze()    # → [B, C_out]\n",
    "        logits = self.classifier(x)   # → [B, num_classes]\n",
    "        probs = torch.sigmoid(logits) if logits.shape[1] == 1 else torch.softmax(logits, dim=1)\n",
    "        return probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
